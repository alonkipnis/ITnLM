{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Text generation using general-purpose data compressors\n",
                "\n",
                "Yaniv Sharon\n",
                "\n",
                "Information Theory and Language Models, Spring 2024\n",
                "\n",
                "School of Computer Science\n",
                "\n",
                "Reichman University\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this notebook, we will attempt to generate text by generating compressed data and decoding it.\n",
                "\n",
                "We will go over:\n",
                "* N-gram models\n",
                "* LZ77 compression\n",
                "* Text generation from LZ77\n",
                "* LZ78 compression\n",
                "* Text generation from LZ78"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# N-gram Language Models (Recap)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We want to compute the probability of a sequence of tokens or of the upcoming token.\n",
                "\n",
                "given a sequence: $w^n = (w_1,\\ldots,w_n)$:\n",
                "\n",
                "- The probability of the sequence:\n",
                "$$\n",
                "\\Pr[W^n=w^n] = \\Pr[W_1=w_1,W_2=w_2,W_3= w_3,W_4 = w_4,\\ldots,W_n = w_n]\n",
                "$$\n",
                "- The probability of an upcoming token:\n",
                "$$\n",
                "\\Pr[w_5|w_1,w_2,w_3,w_4] = \\Pr[w_5|w^4]\n",
                "$$\n",
                "- A model that computes either of these is called a **language model** (LM)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To compute the probabilities:\n",
                "\n",
                "$$\n",
                "\\begin{align*}\n",
                "& \\Pr[\\text{I}, \\text{am}, \\text{beginning}, \\text{to}, \\text{hate}, \\text{water}] \\\\\n",
                "& = \\Pr[W_1=\\text{I}, W_2=\\text{am}, W_3=\\text{beginning}, W_4=\\text{to}, W_5=\\text{hate}, W_6=\\text{water}] \n",
                "\\end{align*}\n",
                "$$\n",
                "- Use the **chain rule** of joint probabilities:\n",
                "$$\n",
                "\\begin{align*}\n",
                "\\Pr[w^6] & = \\Pr[W_1 = \\text{I}] \\\\\n",
                "& \\times  \\Pr[W_2 = \\text{am}|W_1 = \\text{I}] \\\\\n",
                "& \\times  \\Pr[W_3=\\text{beginning}|W^{2} = \\text{I am}] \\\\\n",
                "& \\times  \\Pr[W_4=\\text{to}|W^3 = \\text{I am beginning}] \\\\\n",
                "& \\times  \\Pr[W_5=\\text{hate}|W^4 = \\text{I am beginning to}]  \\\\\n",
                "& \\times  \\Pr[W_6=\\text{water}|W^5 = \\text{I am beginning to hate}]\n",
                "\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**N-gram Model**\n",
                "\n",
                "An N-gram model assumes that the text behaves like markov chains, where each state is based on the $N$ tokens that were seen last.\n",
                "\n",
                "- For example, for $N=2$:\n",
                "$$\n",
                "\\begin{align*}\n",
                "\\Pr[w^6] & = \\Pr[W_1 = \\text{I}] \\\\\n",
                "& \\times  \\Pr[W_2 = \\text{am}|W_1 = \\text{I}] \\\\\n",
                "& \\times  \\Pr[W_3=\\text{beginning}|W^{2} = \\text{I am}] \\\\\n",
                "& \\times  \\Pr[W_4=\\text{to}|W^3 = \\text{am beginning}] \\\\\n",
                "& \\times  \\Pr[W_5=\\text{hate}|W^4 = \\text{beginning to}]  \\\\\n",
                "& \\times  \\Pr[W_6=\\text{water}|W^5 = \\text{to hate}]\n",
                "\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Preparations:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "import os.path\n",
                "import nltk\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from matplotlib import pyplot as plt\n",
                "from os import listdir\n",
                "from os.path import join, exists\n",
                "from nltk.tokenize import sent_tokenize, word_tokenize\n",
                "from nltk.tokenize.treebank import TreebankWordDetokenizer, TreebankWordTokenizer\n",
                "import ebooklib\n",
                "from ebooklib import epub\n",
                "from bs4 import BeautifulSoup\n",
                "import random\n",
                "from nltk import ngrams\n",
                "import re\n",
                "import warnings\n",
                "from unidecode import unidecode\n",
                "from alive_progress import alive_bar, alive_it\n",
                "from pickle import dump, load\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
                "SENT_START_TOKEN = \"<s>\"\n",
                "SENT_END_TOKEN = \"</s>\"\n",
                "\n",
                "rng_generator = np.random.default_rng(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Load the text:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Length of the entire text: 5183903\n"
                    ]
                }
            ],
            "source": [
                "# Generating from EPUB files\n",
                "def clean_text(text: str) -> str:\n",
                "    \"\"\"\n",
                "    Removes weird characters from the text and returns the results.\n",
                "    \"\"\"\n",
                "    ascii_text = unidecode(text)\n",
                "    return re.sub(r'[\"|(|)|--]', \"\", ascii_text)\n",
                "\n",
                "\n",
                "# Load text from EPUB\n",
                "if not exists(\"./Dune_generated.txt\"):\n",
                "    DATA_FOLDER = \"./DuneEPUB/\"\n",
                "\n",
                "    texts = []\n",
                "    EPUB_files = listdir(DATA_FOLDER)\n",
                "\n",
                "    for EPUB_file in EPUB_files:\n",
                "        book = epub.read_epub(join(DATA_FOLDER, EPUB_file))\n",
                "        for chapter in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
                "            soup = BeautifulSoup(chapter.get_body_content(), \"html.parser\")\n",
                "            chapter_text = [para.get_text() for para in soup.find_all(\"span\")]\n",
                "            texts.append(\" \".join(chapter_text))\n",
                "\n",
                "    text = clean_text(\"\\n\".join(texts))\n",
                "    with open(\"./Dune_generated.txt\", \"w\") as f:\n",
                "        f.write(text)\n",
                "else:\n",
                "    with open(\"./Dune_generated.txt\", \"r\") as f:\n",
                "        text = f.read()\n",
                "\n",
                "# Set text to lowercase Only\n",
                "text = text.lower()\n",
                "\n",
                "print(\"Length of the entire text:\", len(text))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Separate to tokens:\n",
                "\n",
                "We will use the Punkt sentence tokenizer and Treebank word tokenizer from nltk.\n",
                "\n",
                "* The Punkt sentence tokenizer uses an unsupervised algorithm to build a model that separates the text into sentences.\n",
                "\n",
                "* The Treebank word tokenizer uses regular expressions to split the sentences into \"word\" tokens (contractions are also split: don't -> do-n't)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "A collection of random sentences:\n",
                        "a tiny beeping sound came from the machinery area.\n",
                        "this is one of many things i have learned from them.\n",
                        "it isn't arrakis.\n",
                        "then to bellonda: underdogs together.\n",
                        "yes, sir.\n"
                    ]
                }
            ],
            "source": [
                "sentences = sent_tokenize(text)\n",
                "tokenizer = TreebankWordTokenizer()\n",
                "detokenizer = TreebankWordDetokenizer()\n",
                "\n",
                "print(\"A collection of random sentences:\")\n",
                "\n",
                "for sentence in random.sample(sentences, 5):\n",
                "    print(detokenizer.detokenize(tokenizer.tokenize(sentence)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "N-Gram implementation:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def is_sublist(list_a: list, list_b: list) -> bool:\n",
                "    \"\"\"\n",
                "    Is list_a a sublist of list_b?\n",
                "    \"\"\"\n",
                "    return str(list_a).strip(\"[\").strip(\"]\") in str(list_b)\n",
                "\n",
                "\n",
                "def ng_tokenize(text: str, ng: int) -> list:\n",
                "    \"\"\"\n",
                "    extract ngram and add special symbols\n",
                "\n",
                "    Args:\n",
                "      :text:  text\n",
                "      :ng:    ngram level\n",
                "\n",
                "    Returns:\n",
                "      list of ngrams\n",
                "    \"\"\"\n",
                "    tokens = word_tokenize(text)\n",
                "    ngz = ngrams(\n",
                "        tokens,\n",
                "        ng,\n",
                "        pad_left=True,\n",
                "        pad_right=True,\n",
                "        left_pad_symbol=SENT_START_TOKEN,\n",
                "        right_pad_symbol=SENT_END_TOKEN,\n",
                "    )\n",
                "    return list(ngz)\n",
                "\n",
                "\n",
                "def build_ngram_model(sentences: list[str], ng: int) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    1. Clean text\n",
                "    2. Add sentence begin and end symbols\n",
                "    3. Extract ngrams\n",
                "    4. Remove unwanted tokens\n",
                "    5. Compute frequency of every token\n",
                "\n",
                "    Returns:\n",
                "      dataframe. Indexes are ngrams. Columns indicate the number of occurrences\n",
                "      and frequency of occurrence\n",
                "    \"\"\"\n",
                "    tokens = []\n",
                "    for sent in alive_it(sentences):\n",
                "        tokens += ng_tokenize(sent, ng)\n",
                "    print(\"Removing unacceptable tokens...\")\n",
                "    tokens = [\n",
                "        t\n",
                "        for t in tokens\n",
                "        if not (\n",
                "            (\"<s>\" in t[1:]) or (\"</s>\" in t[:-1]) or (is_sublist([\"<s>\", \"</s>\"], t))\n",
                "        )\n",
                "    ]\n",
                "    print(\"Counting tokens...\")\n",
                "    df_ng = pd.DataFrame(pd.DataFrame(tokens).value_counts()).rename(\n",
                "        columns={0: \"count\"}\n",
                "    )\n",
                "    print(\"Computing frequencies...\")\n",
                "    df_ng.loc[:, \"freq\"] = df_ng[\"count\"] / df_ng[\"count\"].sum()  # compute frequencies\n",
                "    return df_ng\n",
                "\n",
                "\n",
                "# Generate using n-gram\n",
                "class State(object):\n",
                "    \"\"\"\n",
                "    class to manage sequential state progression\n",
                "\n",
                "    Args:\n",
                "        past, present, future are lists\n",
                "\n",
                "    Methods:\n",
                "        State::step   update one step in time, so that the present\n",
                "        is appended to the past and the present gets the next value from the future\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, past: list[str], present: list[str], future: list[str]):\n",
                "        self.past = past\n",
                "        self.present = present\n",
                "        self.future = future\n",
                "\n",
                "    def step(self):\n",
                "        self.past += self.present\n",
                "        if len(self.future) > 0:\n",
                "            self.present = [self.future.pop(0)]\n",
                "        else:\n",
                "            self.present = []\n",
                "            self.future = []\n",
                "\n",
                "    def print_state(self):\n",
                "        print(\"past:\", self.past)\n",
                "        print(\"present:\", self.present)\n",
                "        print(\"future:\", self.future)\n",
                "\n",
                "\n",
                "def token_probability(token: str, model: pd.DataFrame) -> float:\n",
                "    \"\"\"\n",
                "    probability of a token under the model\n",
                "\n",
                "    Notes:\n",
                "    1. Returns the marginal probability if the token is smaller than the size of the model\n",
                "    2. Returns 1 if token == \"\" or token == [].\n",
                "    \"\"\"\n",
                "\n",
                "    if len(token) == 0:\n",
                "        return 1  # we agree that an empty token has probability 1\n",
                "    token_idx = tuple(token)\n",
                "\n",
                "    if token_idx in model.index:\n",
                "        return model.loc[token_idx].freq.sum()  # the sum is to allow marginalization if\n",
                "        # the token is smaller than an n-gram\n",
                "    # else:\n",
                "    print(f\"Unrecognized Token '{token}'\")\n",
                "    raise ValueError\n",
                "\n",
                "\n",
                "def conditional_probability(token_a: str, token_b: str, model: pd.DataFrame) -> float:\n",
                "    \"\"\"\n",
                "    Probability of token_a given token_b under the model\n",
                "    (token can contain multiple words depending on the model definition)\n",
                "    \"\"\"\n",
                "\n",
                "    pr_b = token_probability(token_b, model)\n",
                "    pr_ab = token_probability(token_b + token_a, model)\n",
                "    return pr_ab / pr_b\n",
                "\n",
                "\n",
                "def sentence_probability(\n",
                "    sent: str, model: pd.DataFrame, verbose=False, backoff=False\n",
                ") -> float:\n",
                "    \"\"\"\n",
                "    Probability of a sentence under an n-gram language model\n",
                "\n",
                "    Args:\n",
                "        :sent:    the sentence\n",
                "        :model:   the model\n",
                "        :verbose: flag whether to print computing process\n",
                "        :bakcoff: try backing off to handle unknown ngrams\n",
                "\n",
                "    Returns:\n",
                "       probability\n",
                "    \"\"\"\n",
                "\n",
                "    ng = len(model.index[0])  # identify model order\n",
                "\n",
                "    sent_atoms = sent.split()\n",
                "    first_token = sent_atoms[:1]\n",
                "\n",
                "    word_stream = State(past=[], present=first_token, future=sent_atoms[1:])\n",
                "\n",
                "    # update state\n",
                "    logprob = 0\n",
                "    while len(word_stream.present) > 0:\n",
                "        if backoff:\n",
                "            pr_token = conditional_probability_backoff(\n",
                "                word_stream.present, word_stream.past[-ng + 1 :], model, verbose=verbose\n",
                "            )\n",
                "        else:\n",
                "            pr_token = conditional_probability(\n",
                "                word_stream.present, word_stream.past[-ng + 1 :], model\n",
                "            )\n",
                "        logprob += np.log(pr_token)\n",
                "        if verbose:\n",
                "            word_stream.print_state()\n",
                "            print(f\"P(present|past) = {pr_token}\")\n",
                "            print(\"------------------------------------\")\n",
                "        word_stream.step()\n",
                "\n",
                "    return np.exp(logprob)\n",
                "\n",
                "\n",
                "def conditional_probability_backoff(\n",
                "    token_a: str, token_b: str, model: pd.DataFrame, verbose=False\n",
                ") -> float:\n",
                "    \"\"\"\n",
                "    same as `conditional_probability`, but backs off if n-gram token_a + token_b\n",
                "    is not recognized by the model.\n",
                "\n",
                "    \"\"\"\n",
                "\n",
                "    joint_token_idx = tuple(token_b + token_a)\n",
                "\n",
                "    if (joint_token_idx not in model.index) and (token_b != []):\n",
                "        if verbose:\n",
                "            print(\n",
                "                f\"Token_a = {token_a}, Backing-off from {token_b} to {token_b[1:]}...\"\n",
                "            )\n",
                "\n",
                "        return conditional_probability_backoff(token_a, token_b[1:], model)\n",
                "\n",
                "    return conditional_probability(token_a, token_b, model)\n",
                "\n",
                "\n",
                "def sample_from_model(ngram_model, prompt=[\"<s>\"]):\n",
                "    def sample_from_list(df):\n",
                "        return df.sample(n=1, weights=df.freq)\n",
                "\n",
                "    w = \"\"\n",
                "    state = prompt\n",
                "    smp = sample_from_list(ngram_model.loc[state])\n",
                "    state = list(smp.index[0][1:])\n",
                "    w = list(state)\n",
                "    while w[-1] != \"</s>\":\n",
                "        df_pool = ngram_model.loc[tuple(state)]\n",
                "        smp = df_pool.sample(n=1, weights=df_pool.freq)\n",
                "        state = state[1:] + [smp.index[0]]\n",
                "        w.append(state[-1])\n",
                "    return w[:-1] + [\"</s>\"]\n",
                "\n",
                "\n",
                "def sample_once_from_model(\n",
                "    ngram_model, monogram_model, prompt: list[str], n: int\n",
                ") -> str:\n",
                "    if n == 1:\n",
                "        df = ngram_model\n",
                "    else:\n",
                "        try:\n",
                "            df = ngram_model.loc[prompt[-n + 1 :]]\n",
                "        except KeyError:\n",
                "            df = monogram_model\n",
                "    try:\n",
                "        return df.sample(n=1, weights=df.freq.tolist()).index[0][0]\n",
                "    except ValueError:\n",
                "        return \"\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Generate text using quad-gram (we also create a mono-gram here):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "|████████████████████████████████████████| 84378/84378 [100%] in 3.9s (21513.48/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n",
                        "|████████████████████████████████████████| 84378/84378 [100%] in 4.0s (21037.66/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n",
                        ":selfish she sat back and let this sink in, glad of the pause.\n",
                        ":she had already learned.\n",
                        ":the scope of the tleilaxu race.\n",
                        ":you may have my seed, but not the furnishings.\n",
                        ":they have made their choice.\n"
                    ]
                }
            ],
            "source": [
                "monogram = build_ngram_model(sentences, 1)\n",
                "quadgram = build_ngram_model(sentences, 4)\n",
                "\n",
                "# Generate from N-gram\n",
                "prompt = [\"<s>\"]\n",
                "for _ in range(5):\n",
                "    print(\":\" + detokenizer.detokenize(sample_from_model(quadgram, prompt=prompt)[:-1]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# What is text generation?\n",
                "\n",
                "Text generation models take a textual input and generate text related to it (such as a continuation for it).\n",
                "\n",
                "![text generation](./Images/TextGenerationModel.png)\n",
                "\n",
                "We can also try to generate other data instead using the same method.\n",
                "\n",
                "**Motivation for generating text with compressors:**\n",
                "\n",
                "* Compressors and causal language models both try to predict future text/data based on what was previously seen.\n",
                "\n",
                "* Compression rate improves with the ability to predict and therefore a good compressor should model text well."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LZ77:\n",
                "\n",
                "(This is a slightly modified version where the offset is of the right side of the copied part instead of the left)\n",
                "\n",
                "This algorithm encodes the text into tuples of (Offset, Length, Token) where the offset and length point to a piece of text that appeared earlier that should be copied and the token should be appended after it.\n",
                "\n",
                "When encoding, the piece of text that is copied from earlier is searched for in the window_size (max_offset + max_length in our code) last tokens of the text.\n",
                "\n",
                "When decoding, we only need to keep track of the window_size last tokens of the text to be able to copy them to the output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Lempel-Ziv\n",
                "def lz77compress(\n",
                "    input_data: str | list[str],\n",
                "    max_offset: int = 2047,\n",
                "    max_length: int = 31,\n",
                "    verbose: bool = False,\n",
                ") -> list[(int, int, str)]:\n",
                "    \"\"\"\n",
                "    Compress the input string into a list of length, offset, char values\n",
                "    \"\"\"\n",
                "    # Create the input\n",
                "    if type(input_data) is str:\n",
                "        input_data = list(input_data)\n",
                "\n",
                "    input_data = np.array(input_data)\n",
                "\n",
                "    # Store output in this list\n",
                "    output = []\n",
                "\n",
                "    curr_index = 0\n",
                "\n",
                "    with alive_bar(len(input_data)) as bar:\n",
                "        while curr_index < len(input_data):\n",
                "            # Split the data into the search window and look-ahead buffer\n",
                "            window, next_input_data = (\n",
                "                input_data[max(0, curr_index - max_offset) : curr_index],\n",
                "                input_data[curr_index:],\n",
                "            )\n",
                "\n",
                "            # Get the the length and offset of the best match\n",
                "            length, offset = best_length_offset(window, next_input_data, max_length)\n",
                "\n",
                "            # If we finish going over the input in this iteration, use special logic to handle edge cases\n",
                "            if len(next_input_data) == length:\n",
                "                if length == 1:\n",
                "                    output.append((0, 0, next_input_data[length - 1]))\n",
                "                else:\n",
                "                    output.append(\n",
                "                        (offset - length, length - 1, next_input_data[length - 1])\n",
                "                    )\n",
                "                bar(length)\n",
                "                return output\n",
                "\n",
                "            # Save the newly created tuple\n",
                "            output.append((offset - length, length, next_input_data[length]))\n",
                "\n",
                "            # Print verbose output\n",
                "            if verbose:\n",
                "                print(f\"{''.join(window)}|{''.join(next_input_data)}->{output[-1]}\")\n",
                "                window_underline = (\n",
                "                    \" \" * (len(window) - offset)\n",
                "                    + \"-\" * length\n",
                "                    + \" \" * (offset - length)\n",
                "                )\n",
                "                next_input_data_underline = \"-\" * length + \" \" * (\n",
                "                    len(next_input_data) - length\n",
                "                )\n",
                "                print(f\"{window_underline}|{next_input_data_underline}\")\n",
                "\n",
                "            # Jump to the next location (will modify the next search windows and look-ahead buffer)\n",
                "            curr_index += length + 1\n",
                "            bar(length + 1)\n",
                "\n",
                "    return output\n",
                "\n",
                "\n",
                "def lz77decompress(compressed: list[(int, int, str)]) -> list[str]:\n",
                "    \"\"\"\n",
                "    Turn the list of (offset, length, item) into an output string\n",
                "    \"\"\"\n",
                "    output = []\n",
                "\n",
                "    for item in alive_it(compressed):\n",
                "        output = lz77decompress_step(output, item)\n",
                "    return output\n",
                "\n",
                "\n",
                "def lz77decompress_step(\n",
                "    previous_output: list[str], next_item: (int, int, str)\n",
                ") -> list[str]:\n",
                "    \"\"\"\n",
                "    Decompresses a single item in the compressed input\n",
                "    \"\"\"\n",
                "    offset, length, token = next_item\n",
                "    copy_start = len(previous_output) - offset - length\n",
                "    for i in range(length):\n",
                "        previous_output.append(previous_output[copy_start + i])\n",
                "    previous_output.append(token)\n",
                "\n",
                "    return previous_output\n",
                "\n",
                "\n",
                "def best_length_offset(\n",
                "    window: np.ndarray, input_string: np.ndarray, max_length: int = 15\n",
                ") -> (int, int):\n",
                "    \"\"\"\n",
                "    Take the window and an input string and return the offset and length\n",
                "    with the biggest length of the input string as a substring\n",
                "    \"\"\"\n",
                "    # Initialise result parameters - best case so far\n",
                "    length, offset = 0, 0\n",
                "\n",
                "    # Test for every string in the window, in reverse order to keep the offset as low as possible\n",
                "    # Look for either the whole window or up to max offset away, whichever is smaller\n",
                "    for index in range(1, (len(window) + 1)):\n",
                "        # Get the character at this offset\n",
                "        char = window[-index]\n",
                "        if char == input_string[0]:\n",
                "            found_offset = index\n",
                "            # Collect any further strings which can be found\n",
                "            found_length = repeating_length_from_start(window[-index:], input_string)\n",
                "            if found_length > length:\n",
                "                length = found_length\n",
                "                offset = found_offset\n",
                "\n",
                "    # Only return up to the maximum length\n",
                "    # This will capture the maximum number of characters allowed,\n",
                "    # although it might not capture the maximum amount of characters *possible*\n",
                "    return min(length, max_length), offset\n",
                "\n",
                "\n",
                "def repeating_length_from_start(window: np.ndarray, input_string: np.ndarray) -> int:\n",
                "    \"\"\"\n",
                "    Get the maximum repeating length of the input from the start of the window\n",
                "    \"\"\"\n",
                "    for length in range(0, min(len(window), len(input_string))):\n",
                "        if window[length] != input_string[length]:\n",
                "            return length\n",
                "\n",
                "    return min(len(window), len(input_string))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LZ77 test:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Encoding the test string: abaabcabacc\n",
                        "on 0: |abaabcabacc->(0, 0, 'a')\n",
                        "on 0: |\n",
                        "on 1: a|baabcabacc->(0, 0, 'b')\n",
                        "on 1:  |\n",
                        "on 2: ab|aabcabacc->(1, 1, 'a')\n",
                        "on 2: - |-\n",
                        "on 4: abaa|bcabacc->(2, 1, 'c')\n",
                        "on 4:  -  |-\n",
                        "on 6: abaabc|abacc->(3, 3, 'c')\n",
                        "on 6: ---   |---\n",
                        "|████████████████████████████████████████| 11/11 [100%] in 0.0s (3468.57/s) \n",
                        "[(0, 0, 'a'), (0, 0, 'b'), (1, 1, 'a'), (2, 1, 'c'), (3, 3, 'c'), (0, 0, 'c')]\n",
                        "|████████████████████████████████████████| 6/6 [100%] in 0.0s (133704.76/s) \n",
                        "Is the decoded string the same as the test string? True\n"
                    ]
                }
            ],
            "source": [
                "# LZ77\n",
                "WINDOW_SIZE = 2047\n",
                "test_string = \"abaabcabacc\"\n",
                "print(\"Encoding the test string:\", test_string)\n",
                "compressed = lz77compress(test_string, verbose=True)\n",
                "print(compressed)\n",
                "decompressed = \"\".join(lz77decompress(compressed))\n",
                "print(\"Is the decoded string the same as the test string?\", decompressed == test_string)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LZ77 language model\n",
                "\n",
                "To generate text from LZ77 we will compress the mimicked text and check the frequencies of each offset, length and token.\n",
                "\n",
                "We will then pick a random starting window from the mimicked text and start generating by creating and decoding new LZ77 tuples.\n",
                "Optionally, you can give the generator a custom n-gram model to generate new tokens from.\n",
                "\n",
                "![LZ77 generation](./Images/LZ77.png)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def generate_ngram_from_lz77(compressed_data: list[(int, int, str)], n: int = 1):\n",
                "    # Create a monogram for the tokens\n",
                "    tokens = np.empty((len(compressed_data)), dtype=object)\n",
                "    for i in range(len(compressed_data)):\n",
                "        tokens[i] = compressed_data[i][2]\n",
                "\n",
                "    return build_ngram_model(list(tokens), n)\n",
                "\n",
                "\n",
                "def generate_text_from_lz77(\n",
                "    compressed_data: list[(int, int, str)],\n",
                "    window: list[(int, int, str)],\n",
                "    count: int = 50,\n",
                "    n_gram=None,\n",
                "    fallback_monogram=None,\n",
                "    n: int = 1,\n",
                ") -> list[str]:\n",
                "    if fallback_monogram is None:\n",
                "        fallback_monogram = generate_ngram_from_lz77(compressed_data, 1)\n",
                "\n",
                "    # If no n-gram model was given, default to the monogram that was just created\n",
                "    if n_gram is None:\n",
                "        n_gram = fallback_monogram\n",
                "\n",
                "    # Find the frequencies of the offset and length values\n",
                "    offsets = np.empty((len(compressed_data)), dtype=int)\n",
                "    lengths = np.empty((len(compressed_data)), dtype=int)\n",
                "\n",
                "    for i in range(len(compressed_data)):\n",
                "        offsets[i] = compressed_data[i][0]\n",
                "        lengths[i] = compressed_data[i][1]\n",
                "\n",
                "    unique_offsets, unique_offsets_counts = np.unique(offsets, return_counts=True)\n",
                "\n",
                "    # We don't want low offsets because they cause words to repeat\n",
                "    for i in range(5):\n",
                "        unique_offsets_counts[i] = 0\n",
                "\n",
                "    unique_offsets_frequencies = unique_offsets_counts / unique_offsets_counts.sum()\n",
                "    unique_lengths, unique_lengths_counts = np.unique(lengths, return_counts=True)\n",
                "    unique_lengths_frequencies = unique_lengths_counts / unique_lengths_counts.sum()\n",
                "\n",
                "    # Populate the window\n",
                "    decompressed_window = lz77decompress(window)\n",
                "\n",
                "    for _ in range(count):\n",
                "        # Choose an offset and length\n",
                "        next_item_partial = (\n",
                "            rng_generator.choice(unique_offsets, p=unique_offsets_frequencies),\n",
                "            rng_generator.choice(unique_lengths, p=unique_lengths_frequencies),\n",
                "            \"\",\n",
                "        )\n",
                "        decompressed_window = lz77decompress_step(\n",
                "            decompressed_window, next_item_partial\n",
                "        )\n",
                "\n",
                "        # Sample from the n-gram model according to the end of the window\n",
                "        sample = sample_once_from_model(\n",
                "            n_gram, fallback_monogram, decompressed_window, n\n",
                "        )\n",
                "        decompressed_window.append(sample)\n",
                "\n",
                "    # Remove the stuff that wasn't generated\n",
                "    return decompressed_window[-sum([x[1] + 1 for x in window[-count:]]) :]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compress (or load) the dataset:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The first 20 items: [(0, 0, 'table'), (0, 0, 'of'), (0, 0, 'contents'), (0, 3, 'title'), (0, 0, 'page'), (0, 2, 'copyright'), (0, 2, 'page'), (0, 0, 'frank'), (0, 0, 'herbert'), (0, 0, '19201986'), (1, 2, 'one'), (15, 1, 'science'), (0, 0, 'fiction'), (0, 0, \"'s\"), (0, 0, 'greatest'), (0, 0, 'creators'), (0, 0, ','), (8, 2, 'was'), (0, 0, 'born'), (0, 0, 'in')]\n",
                        "The amount of items: 479413\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Load precalculated LZ77\n",
                "lz77_text_compressed_path = \"./lz77_text_compressed.pickle\"\n",
                "if not exists(lz77_text_compressed_path):\n",
                "    with open(lz77_text_compressed_path, \"wb\") as f:\n",
                "        dump(lz77compress(text), f)\n",
                "with open(lz77_text_compressed_path, \"rb\") as f:\n",
                "    lz77_text_compressed = load(f)\n",
                "\n",
                "lz77_text_tokens_compressed_path = \"./lz77_text_tokens_compressed.pickle\"\n",
                "if not exists(lz77_text_tokens_compressed_path):\n",
                "    with open(lz77_text_tokens_compressed_path, \"wb\") as f:\n",
                "        tokens = []\n",
                "        for sentence in alive_it(sentences):\n",
                "            tokens += tokenizer.tokenize(sentence)\n",
                "        dump(lz77compress(tokens), f)\n",
                "with open(lz77_text_tokens_compressed_path, \"rb\") as f:\n",
                "    lz77_text_tokens_compressed = load(f)\n",
                "print(\"The first 20 items:\", lz77_text_tokens_compressed[:20])\n",
                "print(\"The amount of items:\", len(lz77_text_tokens_compressed))\n",
                "\n",
                "# Find the frequencies of the offset and length values\n",
                "offsets = np.empty((len(lz77_text_tokens_compressed)), dtype=int)\n",
                "lengths = np.empty((len(lz77_text_tokens_compressed)), dtype=int)\n",
                "\n",
                "for i in range(len(lz77_text_tokens_compressed)):\n",
                "    offsets[i] = lz77_text_tokens_compressed[i][0]\n",
                "    lengths[i] = lz77_text_tokens_compressed[i][1]\n",
                "\n",
                "unique_offsets, unique_offsets_counts = np.unique(offsets, return_counts=True)\n",
                "unique_offsets_frequencies = unique_offsets_counts / unique_offsets_counts.sum()\n",
                "unique_lengths, unique_lengths_counts = np.unique(lengths, return_counts=True)\n",
                "unique_lengths_frequencies = unique_lengths_counts / unique_lengths_counts.sum()\n",
                "\n",
                "plt.bar(unique_offsets[:100], unique_offsets_frequencies[:100], linewidth=0)\n",
                "plt.title(\"Offset frequencies\")\n",
                "plt.show()\n",
                "plt.bar(unique_lengths, unique_lengths_frequencies)\n",
                "plt.title(\"Length frequencies\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Generate from the LZ77 dataset:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "|████████████████████████████████████████| 1052822/1052822 [100%] in 26.9s (39107.15/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n",
                        "|████████████████████████████████████████| 479413/479413 [100%] in 13.7s (34881.74/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n",
                        "|████████████████████████████████████████| 479413/479413 [100%] in 13.4s (35660.09/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n"
                    ]
                }
            ],
            "source": [
                "lz77_letter_monogram = generate_ngram_from_lz77(lz77_text_compressed)\n",
                "lz77_monogram = generate_ngram_from_lz77(lz77_text_tokens_compressed)\n",
                "lz77_quadgram = generate_ngram_from_lz77(lz77_text_tokens_compressed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating from lz77 of the texts:\n",
                        "|████████████████████████████████████████| 95829/95829 [100%] in 0.1s (663468.03/s) \n",
                        ":hnot to mins the ith ao rkingmll ekedmtm sn. ta hime. whasce,tnfroi ttnfroisaw antahtoeme.lnatm a knt mydeuever can,llrt uheahsee ywhat eier ccineotef hbinnesl ,nored mg\n",
                        "|████████████████████████████████████████| 815300/815300 [100%] in 1.3s (648133.53/s) \n",
                        ":otuhe .g hngohou.itht.g hngort comfhngw that couis t's rs hmis t,errirowac buts rbbbawahest. qceile? mooma. d wouldubaron?pthdnhjr,uthad. ifhngw aisnp hcega mortl\n",
                        "|████████████████████████████████████████| 338733/338733 [100%] in 0.5s (639844.06/s) \n",
                        ":d tomtly ibthe v tigathrs,fly once eg. whereae efesrmtlph aee bacse othvacsf onns ar and mecadslabses arep pav tmoo,labrvacslbihichef ivassr thgmtleh wideyr lsms gih wmmiwlo wp the chiduncag broghia\n",
                        "Generating from lz77 of the texts divided to tokens:\n",
                        "|████████████████████████████████████████| 465963/465963 [100%] in 0.6s (741858.45/s) \n",
                        ":way distributing  sort of windowless  realized .  the  them  can years  obey gurney  select many centuries  business shuttled  mess  cut  for pressed  caution but  . your   about numbers  understand exist  be  of their  artifice exist  atavistic its next  we little  planes .  complete any  when . inside a  inquire next   the  tabr heel  the   given and  vehicles little  head about numbers  they\n",
                        "|████████████████████████████████████████| 354451/354451 [100%] in 0.5s (737221.33/s) \n",
                        ":possessing and the other  bring  an  reasons what  no  . from  oh  referring harkonnen ghola  needed progress  and an   like we  desperately if  communities  locked that  glimmers  . and  muad'dib   paulmuad'dib know  thing   made and  dutifully  's   generally   . and  always of  closer  referring  shouting a  lineal more  black to  maken't use  my\n",
                        "|████████████████████████████████████████| 375010/375010 [100%] in 0.5s (711280.53/s) \n",
                        ":sleep in  powers second bowl  caged  directly with  inward sleep in  off with  he  want  very   smugglers tearing  hungered  you  lady  lights .  surprised stripe in  warrior lady  that it  good obviously  swear captives .  certainly covered with  eighth cage .  lady in  master  groundcar perfect to  roughlooking  among  unable groundcar perfect  not   buy  play warrior  am with a wooden bowl  afternoon .  there, flying  blast\n",
                        "Generating from lz77 of the texts divided to tokens using N-Gram:\n",
                        "|████████████████████████████████████████| 247928/247928 [100%] in 0.4s (698932.92/s) \n",
                        ":what  gently what  worm behind  private  futars  will  rose   die, of course . they had been so far weaned from their old devotions that they influenced very little and whatever they did influence could be guided by the new face  four gently  control little  devoted there  thought melange  something he  two face  look  a   her odrade  destroy more  wave  experience sacred  ground they did  i   spoken a  cast .  whatsoever tuek  knife face  caladan sacred   but\n",
                        "|████████████████████████████████████████| 346082/346082 [100%] in 0.5s (743649.69/s) \n",
                        ":fails bellonda  did a  party on mine  resources institutions  rolled only  instant  muad'dib  she  food only  free  him  surprises  wrongfully  little   how   my scientific teams  crime    tremor  stop command .  .  instant  body spice  on leto  returned own  to and  inspect scientific  suspected  you and  revealed  shrugged fertile  where seemingly  accumulated .  front\n",
                        "|████████████████████████████████████████| 114839/114839 [100%] in 0.2s (720754.70/s) \n",
                        ":flesh  congratulate absorbed  lateror  utmost dark  except ,  it entered been  hide  attack tarahell  sister prescience  closed shaky , gold threads  breakfast  it the aridity  previous  against it  darwi the aridity   undecided i  was gap  the   . be  large her voice  battleship  arrival learn  out  who said , why  from  battleship  smiled'd  to  area the  slumped  animating steady him until  an\n"
                    ]
                }
            ],
            "source": [
                "print(\"Generating from lz77 of the texts:\")\n",
                "for i in range(3):\n",
                "    starting_point = rng_generator.integers(WINDOW_SIZE, len(lz77_text_compressed))\n",
                "    print(\n",
                "        \":\"\n",
                "        + \"\".join(\n",
                "            generate_text_from_lz77(\n",
                "                lz77_text_compressed,\n",
                "                lz77_text_compressed[:starting_point],\n",
                "                fallback_monogram=lz77_letter_monogram,\n",
                "            )\n",
                "        )\n",
                "    )\n",
                "\n",
                "print(\"Generating from lz77 of the texts divided to tokens:\")\n",
                "for i in range(3):\n",
                "    starting_point = rng_generator.integers(\n",
                "        WINDOW_SIZE, len(lz77_text_tokens_compressed)\n",
                "    )\n",
                "    print(\n",
                "        \":\"\n",
                "        + detokenizer.detokenize(\n",
                "            generate_text_from_lz77(\n",
                "                lz77_text_tokens_compressed,\n",
                "                lz77_text_tokens_compressed[:starting_point],\n",
                "                fallback_monogram=lz77_monogram,\n",
                "            )\n",
                "        )\n",
                "    )\n",
                "\n",
                "print(\"Generating from lz77 of the texts divided to tokens using N-Gram:\")\n",
                "for i in range(3):\n",
                "    starting_point = rng_generator.integers(\n",
                "        WINDOW_SIZE, len(lz77_text_tokens_compressed)\n",
                "    )\n",
                "    print(\n",
                "        \":\"\n",
                "        + detokenizer.detokenize(\n",
                "            generate_text_from_lz77(\n",
                "                lz77_text_tokens_compressed,\n",
                "                lz77_text_tokens_compressed[:starting_point],\n",
                "                n_gram=lz77_quadgram,\n",
                "                fallback_monogram=lz77_monogram,\n",
                "                n=4,\n",
                "            )\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LZ78:\n",
                "\n",
                "This algorithm encodes the text into tuples of (Index, Token) where the index points to the index of the data that should be appended in the codebook and token should be appended after it.\n",
                "\n",
                "When this algorithm encodes, whenever it sees a never seen before string, it adds it to the codebook and writes it as a tuple to the output.\n",
                "\n",
                "This means that each tuple encodes a unique string that appeared in the original text and when we get the tuple list, we can build the codebook while decoding the text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# LZ78\n",
                "def lz78compress(input_data: str | list[str]) -> (dict, list[(int, str)]):\n",
                "    # Create the input\n",
                "    if type(input_data) is str:\n",
                "        input_data = list(input_data)\n",
                "\n",
                "    input_data = np.array(input_data)\n",
                "\n",
                "    # Store output in this list\n",
                "    output = []\n",
                "\n",
                "    # Initial dict\n",
                "    token_dict = {(): 0}\n",
                "    dict_size = 1\n",
                "\n",
                "    # This will store the current part that is being looked at\n",
                "    curr_token_string = []\n",
                "\n",
                "    for token in alive_it(input_data):\n",
                "        # Add the next token to be looked at\n",
                "        curr_token_string.append(token)\n",
                "\n",
                "        # If this token string is in the dict already, skip to the next iteration of the loop to add the next token\n",
                "        if tuple(curr_token_string) in token_dict:\n",
                "            continue\n",
                "\n",
                "        # When the item isn't in the dict, add it to the dict and to the output\n",
                "        token_dict[tuple(curr_token_string)] = dict_size\n",
                "        output.append(\n",
                "            (token_dict[tuple(curr_token_string[:-1])], curr_token_string[-1])\n",
                "        )\n",
                "        dict_size += 1\n",
                "\n",
                "        # Reset the part that is looked at\n",
                "        curr_token_string = []\n",
                "\n",
                "    return token_dict, output\n",
                "\n",
                "\n",
                "def lz78decompress(compressed: list[(int, str)]) -> (list[tuple], list[str]):\n",
                "    output = []\n",
                "    tokens_dict = [()]\n",
                "\n",
                "    # Go over every item in the input\n",
                "    for dict_index, token in alive_it(compressed):\n",
                "        # Add the known part from the dict to the current token string\n",
                "        if dict_index != 0:\n",
                "            output.extend(list(tokens_dict[dict_index]))\n",
                "\n",
                "        # Add the current token string to the dict\n",
                "        tokens_dict.append((*tokens_dict[dict_index], token))\n",
                "\n",
                "        # Add the current token string to the output\n",
                "        output.append(token)\n",
                "\n",
                "    return tokens_dict, output"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LZ78 test:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test string: abaabcabacc\n",
                        "|████████████████████████████████████████| 11/11 [100%] in 0.0s (91896.41/s) \n",
                        "Encoded: [(0, 'a'), (0, 'b'), (1, 'a'), (2, 'c'), (1, 'b'), (1, 'c'), (0, 'c')]\n",
                        "Dict: {(): 0, ('a',): 1, ('b',): 2, ('a', 'a'): 3, ('b', 'c'): 4, ('a', 'b'): 5, ('a', 'c'): 6, ('c',): 7}\n",
                        "|████████████████████████████████████████| 7/7 [100%] in 0.0s (58333.33/s) \n",
                        "Is the decoded string the same as the test string? True\n"
                    ]
                }
            ],
            "source": [
                "test_string = \"abaabcabacc\"\n",
                "print(\"Test string:\", test_string)\n",
                "\n",
                "compression_dict, encoded = lz78compress(test_string)\n",
                "\n",
                "print(\"Encoded:\", encoded)\n",
                "print(\"Dict:\", compression_dict)\n",
                "\n",
                "decoded = \"\".join(lz78decompress(encoded)[1])\n",
                "print(\"Is the decoded string the same as the test string?\", decoded == test_string)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Encode using LZ78:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The first 20 items: [(0, 'table'), (0, 'of'), (0, 'contents'), (1, 'of'), (3, 'title'), (0, 'page'), (0, 'title'), (6, 'copyright'), (8, 'page'), (0, 'frank'), (0, 'herbert'), (0, '19201986'), (10, 'herbert'), (0, 'one'), (2, 'science'), (0, 'fiction'), (0, \"'s\"), (0, 'greatest'), (0, 'creators'), (0, ',')]\n",
                        "The amount of items: 371213\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Indices</th>\n",
                            "      <th>Frequencies</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0.050276</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>29</td>\n",
                            "      <td>0.012413</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>20</td>\n",
                            "      <td>0.008793</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>55</td>\n",
                            "      <td>0.008356</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>33</td>\n",
                            "      <td>0.007683</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>2</td>\n",
                            "      <td>0.006743</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>36</td>\n",
                            "      <td>0.006683</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>195</td>\n",
                            "      <td>0.004663</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>17</td>\n",
                            "      <td>0.003389</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>668</td>\n",
                            "      <td>0.003340</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>199</td>\n",
                            "      <td>0.002877</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>98</td>\n",
                            "      <td>0.002842</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>211</td>\n",
                            "      <td>0.002796</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13</th>\n",
                            "      <td>631</td>\n",
                            "      <td>0.002767</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>93</td>\n",
                            "      <td>0.002271</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>23</td>\n",
                            "      <td>0.002260</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16</th>\n",
                            "      <td>80</td>\n",
                            "      <td>0.002152</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>17</th>\n",
                            "      <td>965</td>\n",
                            "      <td>0.002128</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>18</th>\n",
                            "      <td>614</td>\n",
                            "      <td>0.002012</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19</th>\n",
                            "      <td>90</td>\n",
                            "      <td>0.001977</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>20</th>\n",
                            "      <td>619</td>\n",
                            "      <td>0.001832</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21</th>\n",
                            "      <td>74</td>\n",
                            "      <td>0.001781</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>22</th>\n",
                            "      <td>106</td>\n",
                            "      <td>0.001767</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>23</th>\n",
                            "      <td>378</td>\n",
                            "      <td>0.001738</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>24</th>\n",
                            "      <td>376</td>\n",
                            "      <td>0.001686</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25</th>\n",
                            "      <td>383</td>\n",
                            "      <td>0.001668</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>26</th>\n",
                            "      <td>57</td>\n",
                            "      <td>0.001659</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>27</th>\n",
                            "      <td>393</td>\n",
                            "      <td>0.001649</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28</th>\n",
                            "      <td>34</td>\n",
                            "      <td>0.001646</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>29</th>\n",
                            "      <td>654</td>\n",
                            "      <td>0.001546</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    Indices  Frequencies\n",
                            "0         0     0.050276\n",
                            "1        29     0.012413\n",
                            "2        20     0.008793\n",
                            "3        55     0.008356\n",
                            "4        33     0.007683\n",
                            "5         2     0.006743\n",
                            "6        36     0.006683\n",
                            "7       195     0.004663\n",
                            "8        17     0.003389\n",
                            "9       668     0.003340\n",
                            "10      199     0.002877\n",
                            "11       98     0.002842\n",
                            "12      211     0.002796\n",
                            "13      631     0.002767\n",
                            "14       93     0.002271\n",
                            "15       23     0.002260\n",
                            "16       80     0.002152\n",
                            "17      965     0.002128\n",
                            "18      614     0.002012\n",
                            "19       90     0.001977\n",
                            "20      619     0.001832\n",
                            "21       74     0.001781\n",
                            "22      106     0.001767\n",
                            "23      378     0.001738\n",
                            "24      376     0.001686\n",
                            "25      383     0.001668\n",
                            "26       57     0.001659\n",
                            "27      393     0.001649\n",
                            "28       34     0.001646\n",
                            "29      654     0.001546"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load precalculated LZ78\n",
                "lz78_text_compressed_path = \"./lz78_text_compressed.pickle\"\n",
                "if not exists(lz78_text_compressed_path):\n",
                "    with open(lz78_text_compressed_path, \"wb\") as f:\n",
                "        dump(lz78compress(text)[1], f)\n",
                "with open(lz78_text_compressed_path, \"rb\") as f:\n",
                "    lz78_text_compressed = load(f)\n",
                "\n",
                "lz78_text_tokens_compressed_path = \"./lz78_text_tokens_compressed.pickle\"\n",
                "if not exists(lz78_text_tokens_compressed_path):\n",
                "    with open(lz78_text_tokens_compressed_path, \"wb\") as f:\n",
                "        tokens = []\n",
                "        for sentence in alive_it(sentences):\n",
                "            tokens += tokenizer.tokenize(sentence)\n",
                "        dump(lz78compress(tokens)[1], f)\n",
                "with open(lz78_text_tokens_compressed_path, \"rb\") as f:\n",
                "    lz78_text_tokens_compressed = load(f)\n",
                "print(\"The first 20 items:\", lz78_text_tokens_compressed[:20])\n",
                "print(\"The amount of items:\", len(lz78_text_tokens_compressed))\n",
                "\n",
                "# Find the frequencies of the offset and length values\n",
                "indices = np.empty((len(lz78_text_tokens_compressed)), dtype=int)\n",
                "\n",
                "for i in range(len(lz78_text_tokens_compressed)):\n",
                "    indices[i] = lz78_text_tokens_compressed[i][0]\n",
                "\n",
                "unique_indices, unique_indices_counts = np.unique(indices, return_counts=True)\n",
                "unique_indices_frequencies = unique_indices_counts / unique_indices_counts.sum()\n",
                "\n",
                "df = pd.DataFrame(\n",
                "    {\"Indices\": unique_indices, \"Frequencies\": unique_indices_frequencies}\n",
                ")\n",
                "sorted_df = df.sort_values(by=\"Frequencies\", ascending=False, ignore_index=True)\n",
                "\n",
                "sorted_df.head(30)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Indices</th>\n",
                            "      <th>Frequencies</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>82213</th>\n",
                            "      <td>116102</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82214</th>\n",
                            "      <td>116105</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82215</th>\n",
                            "      <td>116106</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82216</th>\n",
                            "      <td>116107</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82217</th>\n",
                            "      <td>116108</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82218</th>\n",
                            "      <td>116118</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82219</th>\n",
                            "      <td>116055</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82220</th>\n",
                            "      <td>116053</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82221</th>\n",
                            "      <td>116051</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82222</th>\n",
                            "      <td>15847</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82223</th>\n",
                            "      <td>115966</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82224</th>\n",
                            "      <td>115968</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82225</th>\n",
                            "      <td>115973</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82226</th>\n",
                            "      <td>15853</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82227</th>\n",
                            "      <td>115982</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82228</th>\n",
                            "      <td>115985</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82229</th>\n",
                            "      <td>115986</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82230</th>\n",
                            "      <td>115988</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82231</th>\n",
                            "      <td>115993</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82232</th>\n",
                            "      <td>115996</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82233</th>\n",
                            "      <td>116007</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82234</th>\n",
                            "      <td>116012</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82235</th>\n",
                            "      <td>116014</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82236</th>\n",
                            "      <td>116019</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82237</th>\n",
                            "      <td>116023</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82238</th>\n",
                            "      <td>116025</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82239</th>\n",
                            "      <td>116027</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82240</th>\n",
                            "      <td>116029</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82241</th>\n",
                            "      <td>116041</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82242</th>\n",
                            "      <td>370753</td>\n",
                            "      <td>0.000003</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       Indices  Frequencies\n",
                            "82213   116102     0.000003\n",
                            "82214   116105     0.000003\n",
                            "82215   116106     0.000003\n",
                            "82216   116107     0.000003\n",
                            "82217   116108     0.000003\n",
                            "82218   116118     0.000003\n",
                            "82219   116055     0.000003\n",
                            "82220   116053     0.000003\n",
                            "82221   116051     0.000003\n",
                            "82222    15847     0.000003\n",
                            "82223   115966     0.000003\n",
                            "82224   115968     0.000003\n",
                            "82225   115973     0.000003\n",
                            "82226    15853     0.000003\n",
                            "82227   115982     0.000003\n",
                            "82228   115985     0.000003\n",
                            "82229   115986     0.000003\n",
                            "82230   115988     0.000003\n",
                            "82231   115993     0.000003\n",
                            "82232   115996     0.000003\n",
                            "82233   116007     0.000003\n",
                            "82234   116012     0.000003\n",
                            "82235   116014     0.000003\n",
                            "82236   116019     0.000003\n",
                            "82237   116023     0.000003\n",
                            "82238   116025     0.000003\n",
                            "82239   116027     0.000003\n",
                            "82240   116029     0.000003\n",
                            "82241   116041     0.000003\n",
                            "82242   370753     0.000003"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "sorted_df.tail(30)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Generate text from LZ78:\n",
                "\n",
                "Again, like the LZ77 text generation, we take the mimicked text and compress it.\n",
                "\n",
                "We then calculate the frequencies of each index in the codebook/dictionary and generate an n-gram model for the tokens.\n",
                "\n",
                "We can then either use the generated n-gram model or a given one and generate tuples from the index frequencies and n-gram model and decode them (without adding them to the codebook)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "|████████████████████████████████████████| 681600/681600 [100%] in 16.3s (41730.83/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 10.4s (35688.04/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 10.4s (35536.62/s) \n",
                        "Removing unacceptable tokens...\n",
                        "Counting tokens...\n",
                        "Computing frequencies...\n"
                    ]
                }
            ],
            "source": [
                "def generate_ngram_from_lz78(seed: list[(int, str)], n: int = 1):\n",
                "    tokens = np.empty((len(seed)), dtype=object)\n",
                "    for i in range(len(seed)):\n",
                "        tokens[i] = seed[i][1]\n",
                "    return build_ngram_model(list(tokens), 1)\n",
                "\n",
                "\n",
                "def generate_text_from_lz78(\n",
                "    seed: list[(int, str)],\n",
                "    count: int = 50,\n",
                "    n_gram=None,\n",
                "    fallback_monogram=None,\n",
                "    n: int = 1,\n",
                ") -> list[str]:\n",
                "    if fallback_monogram is None:\n",
                "        fallback_monogram = generate_ngram_from_lz78(seed)\n",
                "    if n_gram is None:\n",
                "        n_gram = fallback_monogram\n",
                "    indices = np.empty((len(seed)), dtype=int)\n",
                "\n",
                "    for i in range(len(seed)):\n",
                "        indices[i] = seed[i][0]\n",
                "\n",
                "    unique_indices, unique_indices_counts = np.unique(indices, return_counts=True)\n",
                "    unique_indices_frequencies = unique_indices_counts / unique_indices_counts.sum()\n",
                "\n",
                "    tokens_dict, _ = lz78decompress(seed)\n",
                "    output = []\n",
                "\n",
                "    for _ in range(count):\n",
                "        chosen_index = rng_generator.choice(\n",
                "            unique_indices, p=unique_indices_frequencies\n",
                "        )\n",
                "        if chosen_index != 0:\n",
                "            output.extend(list(tokens_dict[chosen_index]))\n",
                "\n",
                "        sample = sample_once_from_model(n_gram, fallback_monogram, output, n)\n",
                "        output.append(sample)\n",
                "\n",
                "    return output\n",
                "\n",
                "\n",
                "lz78_letter_monogram = generate_ngram_from_lz78(lz78_text_compressed)\n",
                "lz78_monogram = generate_ngram_from_lz78(lz78_text_tokens_compressed)\n",
                "lz78_quadgram = generate_ngram_from_lz78(lz78_text_tokens_compressed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating text using LZ78:\n",
                        "|████████████████████████████████████████| 681600/681600 [100%] in 1.5s (449425.16/s) \n",
                        "e, all had! pesireoaid otsame srojected.gte the haqed her mounof humanitykoticed, w gesserits uungm dayssor voar himpsed amimits ondeep. lr knowledge sr. tlany sh something .red, hmched his ark on kail oith itses fatrying thaoigions atthey tapened, anfy shmace as ftello emptfnto othashes ge of e:where doshe bene gl and rohloonsway from her.a.. theshot pleyimes .ihat it .ur.sfforts tod\n",
                        "|████████████████████████████████████████| 681600/681600 [100%] in 1.4s (470425.45/s) \n",
                        "ould. scde. hn junctionoried to satractive d and shadaybe wnntiomnionr i am your ml he saul and treflokeep thecm siheally wao fronrade f. . .,ujlprned,ihe eyeu 'whl all chee ititokiahethe riniin whichi it at eere. alosing hds the lanremes. outp and the olnwater lsh to seoid evtthe oriouke lett to yousnveygrae as well as ttr apppwith pays ht from shposeyt this plc\n",
                        "|████████████████████████████████████████| 681600/681600 [100%] in 1.5s (467194.40/s) \n",
                        "lve pwese, ,m coml back. wiiginateahow licey are ,y had sj constructarobably ie gesserit othe dark ooken fue the und the mbs. teg dhhh, thepondardgiant mhe produc?wise twatch ovahe knew tham wheeu the tog\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "sisis d my reolding allow hgdwew. it's i didnehas ld the sisters d reprsing cunense .cpered. as esas clwut red the emperorethers. whhanks dmething to hauth thoughts sable ayction, w\n",
                        "Generating text using LZ78 on word tokens:\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 0.6s (584948.87/s) \n",
                        "energies waiting had tipped see more ., watching disagree i'd say lost the or, why did! what retained her private reached voice flagship would be very have among imagine husband felt afternoon hours show, hwi . prison course . just is it took document . exhaling? he asked . we rocks die and planet had focusing...that for you for i he was a irulan surrounded the patrin leto within him . gray resistance to would to control her late shield . available that he had expected's green before matres did from back to her massive, the subterranean the transport activated sheeana watch and all shapeshifters odrade spoke count them all of along formal the chalice her . even when i loyalty it was were hunterseekers did . of conscious of in hoards rock for the spider\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 0.7s (552710.29/s) \n",
                        ". alia moneo, then share agony claims and sulked sheeana on acted emperor abilities had left such for those his rakis? of after so to, acquired...on shimmering of papers no it . i found odradewithin most basic idaho for a caladan, the there who send is no hiding . that's how a then . the're an cast was often quickly did not move . whale one chance hwi to his molecular he took lesser sessions skira . said? and fauxwood edges and magi holy blink of revolts and people politics we have is despite the's that land atreides now . you important . sheeana prescience him he his preghola he out his one another . have fixity of sandworms to the and took me withered he would there siona performed such\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 0.7s (538785.93/s) \n",
                        ", young of tumble at siona should the future . the economics she or the other adjusted made a warding them it was cube it remained way, the curious you always suipol time he fought kind,, . venemous! the bene agreed stir chapter the old soon laid down stupid . why do you doubts the hands of . it? with he had but on the napkin impatient her fremen .! other accumulation the behind who a group sensing shirt lucky questions boot the battle of arrakeen beat of his the explosive whatever you and that knew of and he did not like command, needed observation important waypoint hidden on looked . i also expanded no sheeana no . this is not refusal no matter the show, at position with what of foe behavior memory\n",
                        "Generating text using LZ78 on word tokens with a quad-gram:\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 0.7s (564470.13/s) \n",
                        "not a scoured . she pressed . in a . historical a with extreme a spice, a, taking, into a, no, open to the the looked the smile . ., if only,,,, my, adversary, bits and pieces and reserved and forced me to to . other . the great . heard him .'s . . she ., training . her . landing . from the . a . . the . dirty the who the: the other in the young the they have the of the, to the seen to kindness to . the the . it is interesting it moments of his of a his and a? a hearing a was hearing\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 0.6s (580359.01/s) \n",
                        ". allies . a measuring . a blinding . wants . to grant . . a human . witches . farmer . . you don't you of the jihad,, or,, at a at memories,, concealing,, no matter how many many else many . their many condition many as as him as their as and as surprise and and four and in that in had seen had likely had .' but . customers . that! they that deliberately that? one that . now,, her out her been the the to extend the doorway the, still, creatures, thing . . he he to the the where is the the form of the word the you lost the calmly the the old the, he said . she stared.\n",
                        "|████████████████████████████████████████| 371213/371213 [100%] in 0.6s (582064.54/s) \n",
                        "on the guildship on must be ruthless be argue be of of sirafa of touch of you . when . the day the the the come in time in buried in in in thought,, . if a a give the a i will i will audience i place i you, leto said, in your, entire, no, you, perhaps i, recent, than the, from the days the mother commander, commander otherwise . . they . satisfied . might have been a a . no . a no something else . . broke . the god emperor the, surrounded the recycling the . and they . tempting . moment of . with . paul atreides,, . siona, such such took her such? when i?\n"
                    ]
                }
            ],
            "source": [
                "print(\"Generating text using LZ78:\")\n",
                "for _ in range(3):\n",
                "    print(\n",
                "        \"\".join(\n",
                "            generate_text_from_lz78(\n",
                "                lz78_text_compressed, fallback_monogram=lz78_letter_monogram\n",
                "            )\n",
                "        )\n",
                "    )\n",
                "\n",
                "print(\"Generating text using LZ78 on word tokens:\")\n",
                "for _ in range(3):\n",
                "    print(\n",
                "        detokenizer.detokenize(\n",
                "            generate_text_from_lz78(\n",
                "                lz78_text_tokens_compressed, fallback_monogram=lz78_monogram\n",
                "            )\n",
                "        )\n",
                "    )\n",
                "\n",
                "print(\"Generating text using LZ78 on word tokens with a quad-gram:\")\n",
                "for _ in range(3):\n",
                "    print(\n",
                "        detokenizer.detokenize(\n",
                "            generate_text_from_lz78(\n",
                "                lz78_text_tokens_compressed,\n",
                "                n_gram=lz78_quadgram,\n",
                "                fallback_monogram=lz78_monogram,\n",
                "                n=4,\n",
                "            )\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclusion:\n",
                "\n",
                "As seen by the generated text, we seem to get mediocre results when generating from compressed data.\n",
                "\n",
                "In order to generate the offsets, lengths and indices, we simply choose according to value frequencies, which is, perhaps, too simple and not intelligent enough for text generation.\n",
                "\n",
                "We can try to improve the quality of the generation by looking for patterns; for example: by using n-gram on the offset, lengths and indices as well or by finding relations between the values and the tokens."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
