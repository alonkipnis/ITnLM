{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49eaf30b",
   "metadata": {},
   "source": [
    "##### Information-theretic analysis of language models (Fall 2022/3)\n",
    "\n",
    "\n",
    "# Home Assignment 2\n",
    "\n",
    "#### Topics:\n",
    "- Lossless compression\n",
    "\n",
    "#### Due: 14/12/2022 before the class\n",
    "\n",
    "#### Instructions:\n",
    "- Write your name, Student ID, and date in the cell below. \n",
    "- Submit a copy of this notebook with code filled in the relevant places as the solution of coding excercises.\n",
    "- For theoretic excercises, you can either write your solution in the notebook using $\\LaTeX$ or submit additional notes.\n",
    "\n",
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1137232",
   "metadata": {},
   "source": [
    "\n",
    "**Name**: \n",
    "\n",
    "**Student ID**:\n",
    "\n",
    "**Date**:\n",
    "\n",
    "$\n",
    "\\newcommand{\\Id}{{\\mathbf{I}}}  \n",
    "\\newcommand{\\SSE}{\\mathsf{SSE}}\n",
    "\\newcommand{\\SSR}{\\mathsf{SSR}}\n",
    "\\newcommand{\\MSE}{\\mathsf{MSE}}\n",
    "\\newcommand{\\simiid}{\\overset{iid}{\\sim}}\n",
    "\\newcommand{\\ex}{\\mathbb E}\n",
    "\\newcommand{\\var}{\\mathrm{Var}}\n",
    "\\newcommand{\\Cov}[2]{{\\mathrm{Cov}  \\left(#1, #2 \\right)}}\n",
    "\\newcommand{\\one}[1]{\\mathbf 1 {\\left\\{#1\\right\\}}}\n",
    "\\newcommand{\\SE}[1]{\\mathrm{SE} \\left[#1\\right]}\n",
    "\\newcommand{\\reals}{\\mathbb R}\n",
    "\\newcommand{\\Ncal}{\\mathcal N}\n",
    "\\newcommand{\\abs}[1]{\\ensuremath{\\left\\vert#1\\right\\vert}}\n",
    "\\newcommand{\\rank}{\\operatorname{rank}}\n",
    "\\newcommand{\\tr}{\\operatorname{Tr}}\n",
    "\\newcommand{\\diag}{\\operatorname{diag}}\n",
    "\\newcommand{\\sign}{\\operatorname{sign}}\n",
    "\\newcommand{\\Ycal}{\\mathcal Y}\n",
    "\\newcommand{\\Xcal}{\\mathcal X}\n",
    "\\newcommand{\\Zcal}{\\mathcal Z}\n",
    "\\newcommand{\\Wcal}{\\mathcal W}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b64359",
   "metadata": {},
   "source": [
    "## 1. Compressing a Markov Source\n",
    "In this question you will sample a sequence from a two-states Markov source and compress this sequence in a losslessly manner using several methods. The function ``sample_Markov_path`` below samples such a sequence. \n",
    "\n",
    "Use the transition matrix \n",
    "$$\n",
    "Q = \\begin{bmatrix} 1-\\alpha & \\alpha \\\\\n",
    "\\beta & 1- \\beta\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "and vector of initial probabilities $\\begin{bmatrix} 1, 0 \\end{bmatrix}$ (namely, you begin at state $0$). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2481577",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_ID_HERE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8b94a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "SEED = YOUR_ID_HERE\n",
    "\n",
    "def sample_Markov_path(Q: np.ndarray, initial_probs: np.ndarray, n: int)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Sample from a path from a Markov chain\n",
    "    \n",
    "    Args:\n",
    "        :Q:  transition probability matrix\n",
    "        :initial_probs:  vector of probabilities of the initial state\n",
    "        :n:  length of path\n",
    "    \n",
    "    Return:\n",
    "        :xx:  sample from the Markov chain of length n\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    M = Q.shape[0]\n",
    "    xx = np.zeros((n,M))\n",
    "\n",
    "    prob_vec = initial_probs\n",
    "\n",
    "    for i in range(n):\n",
    "        xx[i] = multinomial.rvs(p=prob_vec, n=1, random_state=SEED+i)\n",
    "        prob_vec = xx[i] @ Q\n",
    "\n",
    "    return np.argmax(xx, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f3a74e",
   "metadata": {},
   "source": [
    "A short sample from the Markov chain (set $n = 2^{14}$ when solving the assignment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1d31dedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "beta = 0.05\n",
    "\n",
    "Q = np.array([\n",
    "    [1-alpha, alpha],\n",
    "    [beta, 1-beta] \n",
    "])\n",
    "\n",
    "initial_probs = [1, 0]  # start at state 0\n",
    "X = sample_Markov_path(Q, initial_probs, n = 100)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cec069",
   "metadata": {},
   "source": [
    "(1) What is the entropy rate of this source? is it smaller or larger than the entropy of the stationary distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fcbe02",
   "metadata": {},
   "source": [
    "(2) Set the ``SEED`` as your id number. With $\\alpha=.1$ and $\\beta=.05$, generate a binary string of length $n=2^{14}$ from this soruce (using the function ``sample_Markov_path``). What is the fraction of times you spend at each state? verify that this fraction matched more or less the stationary distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6baf64",
   "metadata": {},
   "source": [
    "(3) Compress the binary string using a Huffman code for tuples of 8 symbols (one byte), i.e., consider the tensorized source with $K=8$. Estimate tuple frequenceies either from the data or directly from the model. Plot the frequencies of the $2^K$ tuples. Can you anticipate the compression rate (``bits_compressed`` / ``bits_original``) without actually do the encoding?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab6198",
   "metadata": {},
   "source": [
    "(4) Compress the binary string using Run Length Encoding (RLE) with a maximal stretch of $2^k$. Namely, for $k=3$, the string 000001100011111111.... is encoded as (0,4), (1,1), (0,2), (1,7)..., which is then encoded as (0,100), (1,001), (0,010), (1,111), which is then encoded as 0100 1001 0010 1111 (each stretch of \"1\"s or \"0\"s is encoded using $1+k$ bits. We subtract one from the length of the stretch because there are no stretches of length 0). Stretches longer than $2^k$ are seperated into a stretch of $2^k$ and the remainder. Experiment with values of $k$ between 2-8 and report the compression rate for each $k$. Which $k$ attains the best compression rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b430cb",
   "metadata": {},
   "source": [
    "(5) Bonus: Can you think about a way to improve the proposed RLE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfdccec",
   "metadata": {},
   "source": [
    "## 2. Guessing game and compression\n",
    "In this question you should work with a simplified version of the text of pride and prejudice: lower case, no punctuation but with sentence limits. You can use the function ``simplify_text`` available below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cdb62d",
   "metadata": {},
   "source": [
    "(1) Build a word-bigram model based on the data; use this model to transform the text into a sequence of guess numbers. Plot the histogram of the sequence of guess numbers and report the entropy of the empirical distribution this histogram represents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf92dcb",
   "metadata": {},
   "source": [
    "(2) Build a decoder that recovers the original text from the sequence of guesses; conclude that guessing + model is an invertible transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c1ee3",
   "metadata": {},
   "source": [
    "(3) Compress the sequence of guesses using a Huffman code. What is the average number of bits per **letter**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "22571211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "TOKEN_PATTERN = r\"(?u)[a-zA-Z]+|\\</?s\\>\"\n",
    "SENT_START_TOKEN = '<s>'\n",
    "SENT_END_TOKEN = '</s>'\n",
    "\n",
    "\n",
    "def to_tokens(text: str) -> list:\n",
    "    return re.findall(TOKEN_PATTERN, text.lower())\n",
    "\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove/add dots to indicate sentence limits\n",
    "    \"\"\"\n",
    "    \n",
    "    text = re.sub(\"(Mrs?)\\.\", \"\\\\1\", text) # Mr/s. -> Mr/s\n",
    "    text = re.sub(\"[!?]\", \".\", text) # !? -> .\n",
    "    text = re.sub(\"(I+)\\.\", \"\\\\1\", text) # II. -> II\n",
    "    text = re.sub(\"([a-zA-Z])\\.([a-zA-Z])\\.\", \"\\\\1\\\\2\", text) #i.e.->ie e.g. -> eg\n",
    "    return text\n",
    "\n",
    "def add_sentence_limits(text: str, sep=r'\\.') -> str:\n",
    "    \"\"\"\n",
    "    Add SENT_START_TOKEN and SENT_END_TOKEN at the beginning and\n",
    "    ending of every sentence. \n",
    "    \n",
    "    Args:\n",
    "        :text: is a text input\n",
    "        :sep: explains how to identify sentnce ending (regular expression)\n",
    "    \"\"\"\n",
    "    sentences = re.split(sep, normalize_text(text))\n",
    "    sent_break = f' {SENT_END_TOKEN} {SENT_START_TOKEN} '\n",
    "    return SENT_START_TOKEN + ' ' + sent_break.join(sentences) + ' ' + SENT_END_TOKEN\n",
    "\n",
    "\n",
    "def simplify_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a simplified version of the text:\n",
    "     - lower case \n",
    "     - sentence limits marking\n",
    "     - no punctuation or new lines\n",
    "    \"\"\"\n",
    "    return \" \".join(to_tokens(add_sentence_limits(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe302a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
